{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.manifold import TSNE\n",
    "import pandas as pd\n",
    "import torch\n",
    "import random\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GRU, Embedding,LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sınıflandırıcı=pd.read_csv(\"Kat.csv\") #verilerimi çektim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'iade'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geçici=Sınıflandırıcı[\"category\"]\n",
    "geçici[60000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "yorumlar=Sınıflandırıcı[\"text\"] \n",
    "kategoriler=Sınıflandırıcı[\"category\"]  #kategorilere one hot encoding işlemi yaptım\n",
    "kategoriler= pd.Series(kategoriler)   \n",
    "kategoriler=pd.get_dummies(kategoriler)\n",
    "kategoriler=np.array(kategoriler)\n",
    "yorumlar_tokenize=[] # tokenize edeceğiz sonra stopwordslerden ve köklerden kurtulacağız.\n",
    "yorumlar=list(yorumlar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kategoriler[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cümle in yorumlar:\n",
    "     yorumlar_tokenize.append(cümle.split())   #Tokenize yorumlarımı listeledim şimdi stopwordsları çıkaracağım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dolgu_soz=[]\n",
    "\n",
    "file = open(\"Stopwords.txt\",\"r\", encoding=\"utf-8\")    #stopwords dosyamı aldım listeye akataracağm oradan da stopwordsleri atacağım\"\n",
    "icerik=file.read()\n",
    "icerik=icerik.split('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_words = []                                #filtered words e aktarım yaptım\n",
    "for word in yorumlar_tokenize:\n",
    "    if word not in icerik:\n",
    "        filtered_words.append(word)\n",
    "yorumlar_tokenize=filtered_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 10000                                                         #Kelimelerin bulunma sayılarına göre onları sayıya çevireceğiz                                                                          #Ondan sonra vektörleştireceğiz\n",
    "tokenizer = Tokenizer(num_words=num_words)                                #sonra vektör haline getirilecek\n",
    "tokenizer.fit_on_texts(yorumlar_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tokenizer.texts_to_sequences(yorumlar_tokenize)\n",
    "                                     #burada kelimeleri sayıya çevirdik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens = [len(tokens) for tokens in x]\n",
    "num_tokens = np.array(num_tokens)  #Burada ortalama sayıya baktım"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Güzel ama bütün girdilerin aynı boyutta olması lazım"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86509"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "max_tokens = int(max_tokens)\n",
    "max_tokens                        #Burada çoğunluğa yakın bir sayı belirledim ve fazla olanları atacak az olanlara 0 ekleyeceğim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0],\n",
       "       ...,\n",
       "       [1, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split    #test ve train setine böldük\n",
    "\n",
    "x_train, x_test,y_train,y_test = train_test_split(x,kategoriler,test_size=0.20, random_state=0)\n",
    "y_train=np.array(y_train)                      #Ağımıza vermek için np arrayine çevirdim.\n",
    "y_test=np.array(y_test)\n",
    "\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_padded = pad_sequences(x_train, maxlen=max_tokens)   #padding işlemi yaptım\n",
    "x_test_padded = pad_sequences(x_test, maxlen=max_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_padded=np.array(x_train_padded)\n",
    "x_test_padded=np.array(x_test_padded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # MODELİMİZİ KURALIM #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 50\n",
    "model= Sequential()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Embedding(input_dim=num_words,                     #NUM_WORDS İLE TOPLAM KELİME SAYISINI BELİRLEDİM 50 lik çıktı boyutu \n",
    "                     output_dim=embedding_size,             #verdim yani 50 boyutlu vektörler çıkacak input_length de belirlediğimiz\n",
    "                        input_length=max_tokens,              #token sayısı\n",
    "                    name='embedding_layer'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelimde GRU kullanacağım GRU lar nlp modellerinde oldukça başarılılar\n",
    "aktivasyon fonksiyonunu softmax olarak belirledim çünkü one hot vectorler için en iyisi bu\n",
    "softmax bütün değerleri toplamı 1 olacak şekilde normalize ediyor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.add(GRU(units=24))\n",
    "model.add(Dense(6, activation='softmax'))                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(lr=5*1e-3)                          #Optimizerımız Adam çünkü çok popüler :D learning ratemizide birkaç denemeden sonra girdim\n",
    "model.compile(loss='categorical_crossentropy',     #Loss functionumuz categorical_crossentropy \n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_layer (Embedding)  (None, 125, 50)           500000    \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (None, 24)                5472      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 6)                 150       \n",
      "=================================================================\n",
      "Total params: 505,622\n",
      "Trainable params: 505,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 72000 samples\n",
      "Epoch 1/5\n",
      "72000/72000 [==============================] - 47s 648us/sample - loss: 1.0184 - accuracy: 0.6271\n",
      "Epoch 2/5\n",
      "72000/72000 [==============================] - 45s 627us/sample - loss: 0.5781 - accuracy: 0.7811\n",
      "Epoch 3/5\n",
      "72000/72000 [==============================] - 43s 601us/sample - loss: 0.4637 - accuracy: 0.8240\n",
      "Epoch 4/5\n",
      "72000/72000 [==============================] - 45s 628us/sample - loss: 0.3761 - accuracy: 0.8611\n",
      "Epoch 5/5\n",
      "72000/72000 [==============================] - 47s 660us/sample - loss: 0.2956 - accuracy: 0.8940\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x157b6c3ee08>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_padded, y_train, epochs=5, batch_size=256)    #256lık Batch size ile modelimizi eğittim acc değerimiz 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000/18000 [==============================] - 11s 592us/sample - loss: 0.6408 - accuracy: 0.7829\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(x_test_padded, y_test)      #test sonuçlarıda 0.78"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K                         #Burası Kerasın hata vermesinden dolayı Stackoverflowdan bulduğum çözüm.\n",
    "y_train = K.cast_to_floatx(y_train)\n",
    "y_test=K.cast_to_floatx(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeli ve veriyi modele uygun şekilde optimize etmek #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_labels = np.argmax(y_test, axis =1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x=x_test_padded[:10])\n",
    "y_pred = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "class_weight = class_weight.compute_class_weight('balanced' ,np.unique(y_test_labels) ,y_test_labels)  #buradan modelin dengesine baktım"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99833611, 0.99370653, 1.01936799, 0.98651759, 1.01798439,\n",
       "       0.98522167])"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weight  #vermemize gerek yok zaten gayet dengeli bir verisetimiz var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn\n",
    "from imblearn.under_sampling import InstanceHardnessThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Onur\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass classes=[0 1 2 3 4 5] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ncr = InstanceHardnessThreshold()\n",
    "X_res, y_res = ncr.fit_sample(x_train_padded, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelin Kullanımı #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = tokenizer.word_index\n",
    "mapr = dict(zip(idx.values(), idx.keys()))\n",
    "def tokens_to_string(tokens):\n",
    "    words = [mapr[token] for token in tokens if token!=0]\n",
    "    text = ' '.join(words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bir bu hizmetlerini kart kartın'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_to_string([2,3,45,6,345])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Şimdi Bir girdi verdiğimizde bize onun kategorisini söyleyen fonksiyonu yazalım"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_text(string):   #Modele uygun hale getiren fonksiyonumuz hazır\n",
    "    splitted=string.split()\n",
    "    tokens = [str_To_Txt[token] for token in splitted]\n",
    "    zero=0\n",
    "    while(len(tokens)<max_tokens):tokens.append(zero)\n",
    "    tokens=np.array(tokens)\n",
    "    tokens=tokens.reshape(1,125)\n",
    "    pred=model.predict(tokens)\n",
    "    text3=one_hot_to_text(pred)\n",
    "    \n",
    "    return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_to_text(ohv):   #Tahmini texte çeviriyor\n",
    "    maks=np.argmax(ohv) #1 kredi kartı,iptal,hesap,musteri_hizmetleri,iade,kredi\n",
    "    if(maks==4):\n",
    "        d=\"kredi-kartı\"\n",
    "        return d\n",
    "    if(maks==2):\n",
    "        d=\"iptal\"\n",
    "        return d  \n",
    "    if(maks==0):\n",
    "        d=\"hesap\"\n",
    "        return d  \n",
    "    if(maks==5):\n",
    "        d=\"mus_hiz\"\n",
    "        return d\n",
    "    if(maks==1):\n",
    "        d=\"iade\"\n",
    "        return d  \n",
    "    if(maks==3):\n",
    "        d=\"kredi\"\n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=tokenizer.word_index\n",
    "str_To_Txt = dict(zip(idx.keys(), idx.values()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "058e5416a93c4299ab20132e8ff6b7dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='Bu Ufak ipynb uygulamasına hoşgeldin!', disabled=True)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "widgets.Text(value='Bu Ufak ipynb uygulamasına hoşgeldin!', disabled=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-129-73a1e7733bf0>, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-129-73a1e7733bf0>\"\u001b[1;36m, line \u001b[1;32m13\u001b[0m\n\u001b[1;33m    widgets.Label(value='Kategori:'),\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "a=widgets.Box(\n",
    "       \n",
    "    [   \n",
    "        widgets.Button(\n",
    "    description='Click me',\n",
    "    disabled=False,\n",
    "    button_style='info', \n",
    "    tooltip='Click me',\n",
    "    icon='check' \n",
    "),\n",
    "        \n",
    "        widgets.Textarea(value=\"Sınıflandırmak İstediğin cümleyi gir\")\n",
    "        widgets.Label(value='Kategori:'),\n",
    "        widgets.RadioButtons(\n",
    "            options=[\n",
    "                'Kredi-Kartı',\n",
    "                'Kredi',\n",
    "                'İptal',\n",
    "                'hesap',\n",
    "                'iade' \n",
    "            ],\n",
    "            layout={'width': 'max-content'}\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8015b090ce2348dd81d12e1fbf34aa88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Click Me!', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ff4778ee9aa4d79a0467cc4539ae36f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd0fcead14a54a34b49f4490917230e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(options=('Kredi-Kartı', 'Kredi', 'İptal', 'hesap', 'iade'), value='Kredi-Kartı')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da558810a4e241bcafa3756e40e09749",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='Sınıflandırmak İstediğin cümleyi gir')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "button = widgets.Button(description=\"Click Me!\")\n",
    "output = widgets.Output()\n",
    "seçenek= widgets.RadioButtons(\n",
    "            options=[\n",
    "                'Kredi-Kartı',\n",
    "                'Kredi',\n",
    "                'İptal',\n",
    "                'hesap',\n",
    "                'iade'\n",
    "            ]\n",
    "                )\n",
    "text_Box=widgets.Textarea(value=\"Sınıflandırmak İstediğin cümleyi gir\")\n",
    "display(button, output,seçenek,text_Box)\n",
    "\n",
    "@output.capture()\n",
    "def on_button_clicked(b):\n",
    "    result=string_to_text(text_Box.value)\n",
    "    print(result)\n",
    "   \n",
    "\n",
    "button.on_click(on_button_clicked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sınıflandırmasgsdgdsgk İstediğin cümleyi gir'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n",
      "kredi\n",
      "çekmek\n",
      "istiyorum\n"
     ]
    }
   ],
   "source": [
    "onur=onur.split()\n",
    "for a in onur:\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.2303501e-03, 4.5058745e-04, 7.4079544e-05, 9.9762923e-01,\n",
       "        8.1433900e-05, 5.3437956e-04]], dtype=float32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_train_padded[44].reshape(1,125))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8157809 , 0.04967908, 0.0018088 , 0.00242087, 0.0109795 ,\n",
       "        0.11933084]], dtype=float32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_to_text( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
